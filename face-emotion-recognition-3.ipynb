{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 引入一些需要用到的库\n该实验仍属于进阶，由于使用新的数据集，所以将其分到第三个实验中\n\n由于时间较为紧张，该实验较为粗糙，结果展示并未做全","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport skimage.io\nimport keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import DenseNet169\n\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras import optimizers\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:42.777520Z","iopub.execute_input":"2022-07-11T14:16:42.778081Z","iopub.status.idle":"2022-07-11T14:16:51.759570Z","shell.execute_reply.started":"2022-07-11T14:16:42.777970Z","shell.execute_reply":"2022-07-11T14:16:51.758679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.AUC(name='prc', curve='PR')\n]\nprint(\"1\")","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:51.761288Z","iopub.execute_input":"2022-07-11T14:16:51.762076Z","iopub.status.idle":"2022-07-11T14:16:54.975021Z","shell.execute_reply.started":"2022-07-11T14:16:51.762017Z","shell.execute_reply":"2022-07-11T14:16:54.974189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 绘制函数","metadata":{}},{"cell_type":"code","source":"def Train_Val_Plot2(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,recall,val_recall,prc,val_prc):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5,ax6) = plt.subplots(1,6, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(recall) + 1), recall)\n    ax5.plot(range(1, len(val_recall) + 1), val_auc)\n    ax5.set_title('History of recall')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('recall')\n    ax5.legend(['training', 'validation'])\n    \n    ax6.plot(range(1, len(prc) + 1), prc)\n    ax6.plot(range(1, len(val_prc) + 1), val_prc)\n    ax6.set_title('History of prc')\n    ax6.set_xlabel('Epochs')\n    ax6.set_ylabel('prc')\n    ax6.legend(['training', 'validation'])\n    \n    recall,val_recall,prc,val_prc\n    \n#     ax5.plot(range(1, len(f1) + 1), f1)\n#     ax5.plot(range(1, len(val_f1) + 1), val_f1)\n#     ax5.set_title('History of F1-score')\n#     ax5.set_xlabel('Epochs')\n#     ax5.set_ylabel('F1 score')\n#     ax5.legend(['training', 'validation'])\n\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:54.976581Z","iopub.execute_input":"2022-07-11T14:16:54.977225Z","iopub.status.idle":"2022-07-11T14:16:54.992558Z","shell.execute_reply.started":"2022-07-11T14:16:54.977186Z","shell.execute_reply":"2022-07-11T14:16:54.991674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 数据集的处理（训练集，测试集，验证集）","metadata":{}},{"cell_type":"code","source":"def initDataGens():\n    \n    train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   validation_split = 0.2,\n                                   rotation_range=0.3, #5,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   #zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=False,\n                                   fill_mode='nearest')\n\n#     valid_datagen = ImageDataGenerator(rescale = 1./255,\n#                                   validation_split = 0.2\n#                                   )\n\n    test_datagen  = ImageDataGenerator(rescale = 1./255)\n\n\n    return train_datagen, test_datagen, test_datagen","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:54.996445Z","iopub.execute_input":"2022-07-11T14:16:54.996742Z","iopub.status.idle":"2022-07-11T14:16:55.012725Z","shell.execute_reply.started":"2022-07-11T14:16:54.996716Z","shell.execute_reply":"2022-07-11T14:16:55.011690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initDataSets(train, test, train_datagen, valid_datagen, test_datagen, classes_):\n    \n    train_dataset  = train_datagen.flow_from_directory(directory = train,\n                                                   target_size = (48,48),\n                                                   class_mode = 'categorical',\n                                                   classes=classes_,\n                                                   subset = 'training',\n                                                   batch_size = 64)\n\n    valid_dataset = train_datagen.flow_from_directory(directory = train,\n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  classes=classes_,\n                                                  subset = 'validation',\n                                                  batch_size = 64)\n    \n#     valid_dataset = valid_datagen.flow_from_directory(directory = train,'../input/fer2013/train',\n#                                                   target_size = (48,48),\n#                                                   class_mode = 'categorical',\n#                                                   classes=classes_,\n#                                                   subset = 'validation',\n#                                                   batch_size = 64)\n\n    test_dataset = test_datagen.flow_from_directory(directory = test, \n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  classes=classes_,\n                                                  batch_size = 64)\n\n\n    return train_dataset, valid_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.014707Z","iopub.execute_input":"2022-07-11T14:16:55.015296Z","iopub.status.idle":"2022-07-11T14:16:55.027778Z","shell.execute_reply.started":"2022-07-11T14:16:55.015256Z","shell.execute_reply":"2022-07-11T14:16:55.026990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 构建模型","metadata":{}},{"cell_type":"code","source":"def updateBaseModel(base_model, num_classes):\n    \n    for layer in base_model.layers[:]:\n        layer.trainable=True\n    \n    # Building Model\n    model=Sequential()\n    model.add(base_model)\n    model.add(Dropout(0.5))\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(32,kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(32,kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(32,kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.029235Z","iopub.execute_input":"2022-07-11T14:16:55.030256Z","iopub.status.idle":"2022-07-11T14:16:55.043228Z","shell.execute_reply.started":"2022-07-11T14:16:55.030214Z","shell.execute_reply":"2022-07-11T14:16:55.042361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_DG(data_generator):\n    counter = Counter(data_generator.classes)\n    data_items = counter.items() # dict_items([(0, 1648), (1, 3614)])\n    l = list(counter.items())\n    print(l)\n  \n    plt.bar(range(len(l)), [val[1] for val in l], align='center')\n    plt.xticks(range(len(l)), [val[0] for val in l])\n    plt.xticks(rotation=70)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.044906Z","iopub.execute_input":"2022-07-11T14:16:55.045557Z","iopub.status.idle":"2022-07-11T14:16:55.057415Z","shell.execute_reply.started":"2022-07-11T14:16:55.045518Z","shell.execute_reply":"2022-07-11T14:16:55.056565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getClassWeights(train_dataset):\n    \n    counter = Counter(train_dataset.classes)                          \n    max_val = float(max(counter.values()))       \n    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}    \n    print(class_weights)\n\n    return class_weights","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.059008Z","iopub.execute_input":"2022-07-11T14:16:55.059991Z","iopub.status.idle":"2022-07-11T14:16:55.068726Z","shell.execute_reply.started":"2022-07-11T14:16:55.059952Z","shell.execute_reply":"2022-07-11T14:16:55.067833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotModel(model):\n    \n    plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n    Image(filename='convnet.png')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.069852Z","iopub.execute_input":"2022-07-11T14:16:55.071651Z","iopub.status.idle":"2022-07-11T14:16:55.080241Z","shell.execute_reply.started":"2022-07-11T14:16:55.071602Z","shell.execute_reply":"2022-07-11T14:16:55.079335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAllForTraining(model, save_h5_to_path, epochs_):\n    \n    lrd = ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.5,\n        patience=7,\n        min_lr=1e-7,\n        verbose=1,\n    )\n\n    mcp_5categories = ModelCheckpoint(save_h5_to_path)\n\n    # es = EarlyStopping(verbose=1, patience=20)\n    es = EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=0.00005,\n        patience=11,\n        verbose=1,\n        restore_best_weights=True,\n    )\n\n    # optimizers.Adam(learning_rate=1e-3, decay=1e-3 / epochs)\n    # model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)\n    t_epochs = epochs_\n\n    optim = optimizers.Adam(learning_rate=1e-3, decay=1e-3 / t_epochs)\n    model.compile(optimizer=optim, loss='categorical_crossentropy',metrics=METRICS)\n    model.summary()\n\n    return lrd, mcp_5categories, es, t_epochs, model, t_epochs","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.083109Z","iopub.execute_input":"2022-07-11T14:16:55.083709Z","iopub.status.idle":"2022-07-11T14:16:55.092103Z","shell.execute_reply.started":"2022-07-11T14:16:55.083672Z","shell.execute_reply":"2022-07-11T14:16:55.091312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotConfusionMatrix(model, test_dataset, num_of_test_samples, batch_size, target_names):\n    \n    #Confution Matrix and Classification Report\n    Y_pred = model.predict(test_dataset, num_of_test_samples // batch_size+1)\n    y_pred = np.argmax(Y_pred, axis=1)\n    print('Confusion Matrix')\n    cm = confusion_matrix(test_dataset.classes, y_pred)\n    print('Classification Report')\n    print(classification_report(test_dataset.classes, y_pred, target_names=target_names))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n    disp.plot(cmap=plt.cm.Blues)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.094712Z","iopub.execute_input":"2022-07-11T14:16:55.095027Z","iopub.status.idle":"2022-07-11T14:16:55.107234Z","shell.execute_reply.started":"2022-07-11T14:16:55.094989Z","shell.execute_reply":"2022-07-11T14:16:55.106372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 模型训练","metadata":{}},{"cell_type":"code","source":"# 7 emotions\n\ntarget_names = ['Anger','Disgust','Fear','Happy','Neutral','Sad','Surprise']\nnum_classes = len(target_names)\ntrain_path = '../input/fer2013pluscleanedaugmballanced1/train'\ntest_path = '../input/fer2013pluscleanedaugmballanced1/test'\nsave_model_h5_to_path = 'MobileNet-Classification-7emotions-CNN.h5'\nepochs = 100\n\ntrain_datagen, valid_datagen, test_datagen = initDataGens()\ntrain_dataset, valid_dataset, test_dataset = initDataSets(train_path, test_path, train_datagen, valid_datagen, test_datagen, target_names)\nclass_weights = getClassWeights(train_dataset)\nplot_DG(train_dataset)\n\n# base_model = tf.keras.applications.ResNet50(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")\nbase_model = tf.keras.applications.MobileNet(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")\n\n# model = build_net(optimizers.SGD(learning_rate=0.01, momentum=0.9), 7, METRICS)\n\nmodel = updateBaseModel(base_model, len(target_names))\nlrd, mcp_5categories, es, t_epochs, model, t_epochs = getAllForTraining(model, save_model_h5_to_path, epochs)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:16:55.108255Z","iopub.execute_input":"2022-07-11T14:16:55.110105Z","iopub.status.idle":"2022-07-11T14:17:18.059734Z","shell.execute_reply.started":"2022-07-11T14:16:55.110068Z","shell.execute_reply":"2022-07-11T14:17:18.058921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history1 = model.fit(train_dataset,validation_data=test_dataset,epochs = t_epochs,verbose = 1,callbacks=[lrd,mcp_5categories,es], class_weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:17:18.068338Z","iopub.execute_input":"2022-07-11T14:17:18.071089Z","iopub.status.idle":"2022-07-11T14:18:05.778101Z","shell.execute_reply.started":"2022-07-11T14:17:18.071047Z","shell.execute_reply":"2022-07-11T14:18:05.776855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 输出结果","metadata":{}},{"cell_type":"code","source":"Train_Val_Plot2(history1.history['accuracy'],history1.history['val_accuracy'],\n               history1.history['loss'],history1.history['val_loss'],\n               history1.history['auc'],history1.history['val_auc'],\n               history1.history['precision'],history1.history['val_precision'],\n               history1.history['recall'],history1.history['val_recall'],\n               history1.history['prc'],history1.history['val_prc']\n              )","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:18:05.779464Z","iopub.status.idle":"2022-07-11T14:18:05.780155Z","shell.execute_reply.started":"2022-07-11T14:18:05.779903Z","shell.execute_reply":"2022-07-11T14:18:05.779930Z"},"trusted":true},"execution_count":null,"outputs":[]}]}